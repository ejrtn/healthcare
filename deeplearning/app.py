import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

# Grad-CAM ë¼ì´ë¸ŒëŸ¬ë¦¬
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

# ------------------------------------------------------------------
# 1. ì„¤ì • (ë³¸ì¸ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìˆ˜!)
# ------------------------------------------------------------------
MODEL_PATH = 'x-ray_model_denseNet-121_v4.pth'
TEST_IMAGE_PATH = './data/archive/images_resized_224/test_list/00000041_002.png'

NUM_CLASSES = 14
IMG_SIZE = 224
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

LABELS = [
    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',
    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',
    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'
]

# ------------------------------------------------------------------
# 2. ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# ------------------------------------------------------------------
def load_model():
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = models.densenet121(weights=None)
    num_features = model.classifier.in_features
    
    model.classifier = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_features, NUM_CLASSES)
    )
    
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except FileNotFoundError:
        print(f"âŒ Error: ëª¨ë¸ íŒŒì¼({MODEL_PATH})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    model.to(device)
    model.eval()
    return model

# ------------------------------------------------------------------
# [í•µì‹¬] 3. ì§ê´€ì ì¸ íˆíŠ¸ë§µ ìƒì„± í•¨ìˆ˜ (Clean Heatmap)
# ------------------------------------------------------------------
def visualize_cam_clean(model, input_tensor, original_img, target_category_index, threshold=0.2):
    """
    íŒŒë€ìƒ‰ ë°°ê²½ì„ ì—†ì• ê³ , ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ ë¶‰ê²Œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
    threshold: ì´ ê°’ë³´ë‹¤ ë‚®ì€ ì¤‘ìš”ë„ëŠ” íˆ¬ëª…í•˜ê²Œ ì²˜ë¦¬ (0.0 ~ 1.0)
    """
    # 1. Grad-CAM ê°ì²´ ìƒì„±
    target_layers = [model.features[-1]] # DenseNet ë§ˆì§€ë§‰ ì¸µ
    cam = GradCAM(model=model, target_layers=target_layers)
    targets = [ClassifierOutputTarget(target_category_index)]

    # 2. íˆíŠ¸ë§µ ì¶”ì¶œ (0~1 ì‚¬ì´ ê°’)
    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]

    # 3. ë…¸ì´ì¦ˆ ì œê±° (Thresholding)
    # ì¤‘ìš”ë„ê°€ ë‚®ì€ ë¶€ë¶„(ë°°ê²½)ì€ 0ìœ¼ë¡œ ë§Œë“¦
    grayscale_cam[grayscale_cam < threshold] = 0

    # 4. ì»¬ëŸ¬ë§µ ì ìš© (JET: íŒŒë‘~ë¹¨ê°•, í•˜ì§€ë§Œ íŒŒë‘ì€ ì•„ë˜ì—ì„œ ì œê±°ë¨)
    heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255.0
    heatmap = heatmap[..., ::-1] # OpenCV BGR -> RGB ë³€í™˜

    # 5. ì›ë³¸ê³¼ í•©ì„± (Alpha Blending)
    # íˆíŠ¸ë§µ ê°’ì´ ìˆëŠ” ë¶€ë¶„ë§Œ ìƒ‰ì„ ì…íˆê³ , ë‚˜ë¨¸ì§€ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ë‘ 
    cam_image = original_img.copy()
    
    # íˆíŠ¸ë§µì˜ ê°•ë„(grayscale_cam)ë¥¼ íˆ¬ëª…ë„(Alpha)ë¡œ ì‚¬ìš©
    # ê°•í•œ ë¶€ë¶„ì€ ë¹¨ê°›ê²Œ, ì•½í•œ ë¶€ë¶„ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ
    for c in range(3):
        cam_image[:, :, c] = original_img[:, :, c] * (1 - grayscale_cam) + heatmap[:, :, c] * grayscale_cam

    # ê°’ ë²”ìœ„ ì•ˆì „ì¥ì¹˜ (0~1)
    cam_image = np.clip(cam_image, 0, 1)
    
    return cam_image

# ------------------------------------------------------------------
# 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ------------------------------------------------------------------
def run_analysis():
    # 1. ëª¨ë¸ ì¤€ë¹„
    model = load_model()
    if model is None: return

    # 2. ì´ë¯¸ì§€ ì¤€ë¹„
    if not os.path.exists(TEST_IMAGE_PATH):
        print(f"âŒ Error: ì´ë¯¸ì§€ íŒŒì¼({TEST_IMAGE_PATH})ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    raw_image = Image.open(TEST_IMAGE_PATH).convert('RGB')
    
    # ì‹œê°í™”ìš© ì´ë¯¸ì§€ (0~1 ì‹¤ìˆ˜í˜•)
    vis_image = np.array(raw_image.resize((IMG_SIZE, IMG_SIZE))) / 255.0
    
    # ëª¨ë¸ ì…ë ¥ìš©
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    input_tensor = transform(raw_image).unsqueeze(0).to(device)

    # 3. ì˜ˆì¸¡
    print("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.sigmoid(output).cpu().numpy()[0]

    # 4. ê²°ê³¼ í…ìŠ¤íŠ¸
    top3_indices = probs.argsort()[-3:][::-1]
    
    print("\n" + "="*40)
    print(f"ğŸ§ª ë¶„ì„ ê²°ê³¼ (íŒŒì¼: {os.path.basename(TEST_IMAGE_PATH)})")
    print("="*40)
    for idx in top3_indices:
        print(f" -> {LABELS[idx]}: {probs[idx]*100:.2f}%")
    print("="*40)

    # 5. [ìˆ˜ì •ë¨] ì§ê´€ì ì¸ íˆíŠ¸ë§µ ìƒì„±
    highest_idx = top3_indices[0]
    
    # threshold=0.2 : í•˜ìœ„ 20%ì˜ ì•½í•œ ì‹ í˜¸ëŠ” ì§€ì›Œì„œ ë°°ê²½ì„ ê¹¨ë—í•˜ê²Œ ë§Œë“¦
    cam_image = visualize_cam_clean(model, input_tensor, vis_image, highest_idx, threshold=0.2)

    # 6. í™”ë©´ ì¶œë ¥
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    plt.imshow(vis_image)
    plt.title("Original X-ray")
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    plt.imshow(cam_image)
    plt.title(f"AI Focus: {LABELS[highest_idx]} ({probs[highest_idx]*100:.1f}%)")
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()

# ì‹¤í–‰
if __name__ == "__main__":
    run_analysis()